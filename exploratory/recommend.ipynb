{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change directory to VSCode workspace root so that relative path loads work correctly. Turn this addition off with the DataScience.changeDirOnImportExport setting\n",
    "# ms-python.python added\n",
    "import os\n",
    "try:\n",
    "\tos.chdir(os.path.join(os.getcwd(), 'cornell\\\\CDS\\pathways-vis'))\n",
    "\tprint(os.getcwd())\n",
    "except:\n",
    "\tpass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Recommending classes\n",
    " In this notebook, I'll be working toward a recommendation algorithm which can\n",
    " make useful class recommendations to students. This may take any of several\n",
    " different forms, described below:\n",
    "\n",
    " ## General Recommendations\n",
    " A good starting point, we may want to just accept one set of classes and find\n",
    " a set of classes which are also closely related or interesting.\n",
    "\n",
    " ## Point-to-Point\n",
    " We may see students define a set of classes they have taken, and a set of\n",
    " classes they would like to take. In this case, the algorithm would ideally\n",
    " provide a set of classes which either lie between those classes or would just\n",
    " also be generally interesting to that student.\n",
    "\n",
    " ## Exploratory\n",
    " This is much more challenging - we may want to recommend classes that the\n",
    " student has not yet demonstrated an interest in, but could potentially find\n",
    " intriguing. I don't know if we have the data to do this, but it would align\n",
    " closely with Pf. Kilczec's ideas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import test_extract\n",
    "from test_extract import Data\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List\n",
    "\n",
    "FILENAME = \"data/CIS_enrollment.csv\"\n",
    "ENCODING = \"iso-8859-1\"\n",
    "\n",
    "data = Data(FILENAME)\n",
    "raw  = pd.read_csv(FILENAME, encoding=ENCODING)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Student-wise\n",
    " One easy way to make recommendations is to identify students who have taken\n",
    " the same or a similar set of courses and see what else they tend to take."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Crosslisting\n",
    " We actually run into a fairly important problem here - crosslisting.\n",
    " Crosslisted courses, which are for our purposes the same, are distinct in the\n",
    " data model which greatly limits the accuracy of any model we build."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def translate(codes: List[str]) -> List[test_extract.Course]:\n",
    "    \"\"\" Convert course codes into Course objects \"\"\"\n",
    "    courses = []\n",
    "    for code in codes:\n",
    "        courses.append(data.filterCourses(lambda c: c.id==code)[0])\n",
    "    return courses\n",
    "\n",
    "def show_results(df: pd.DataFrame):\n",
    "    df['c'] = df.course.map(lambda code: 'C1' if code in beta else 'C0')\n",
    "    df['size'] = df.course.map(lambda c: len(c.students))\n",
    "    top = df.head(20)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,5))\n",
    "    plt.subplots_adjust(wspace=0.4)\n",
    "\n",
    "    ax1.scatter(df['size'], df.score, color=df.c)\n",
    "    ax1.set_title(\"Overall Score Distribution\")\n",
    "    ax1.set_xlabel(\"Number of Students\")\n",
    "    ax1.set_ylabel(\"Score\")\n",
    "\n",
    "\n",
    "    ax2.barh(top.code, top.score, color=top.c)\n",
    "    ax2.set_title(\"Class Recommendations\")\n",
    "    ax2.set_xlabel(\"Score\")\n",
    "    ax2.invert_yaxis()\n",
    "\n",
    "    fig.show()\n",
    "    return df.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recommend_bystudent(courses: List[test_extract.Course]) -> pd.DataFrame:\n",
    "    students = [course.students for course in courses]\n",
    "\n",
    "    targets = set.intersection(*students)\n",
    "\n",
    "    courses = data.getCourses()\n",
    "    scores = map(lambda c: len(set.intersection(targets, c.students)), courses)\n",
    "\n",
    "    recommendations = {\n",
    "        'code': [course.id for course in courses],\n",
    "        'course': courses,\n",
    "        'score' : scores\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame(recommendations).sort_values('score', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = translate([\"CS2110\", \"CS2800\", \"CS2850\", \"CS1110\"])\n",
    "\n",
    "df = recommend_bystudent(beta)\n",
    "show_results(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Neat! This is actually pretty bad though. For one thing, we aren't\n",
    " accommodating for class sizes *at all*, so it's very heavily biased toward\n",
    " large classes. Note that it ranks ECON 1110, an almost completely unrelated\n",
    " course, above most relevant computer science electives. This is because Intro\n",
    " Microecon is just a massive class, so it's bound to have more of our target\n",
    " students in it than any smaller elective class. We can solve this. Instead of\n",
    " counting how many target students are in each class, let's count what\n",
    " proportion of the students who take each class are in our target population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recommend_bystudent_prop(courses: List[test_extract.Course], threshold=20) -> pd.DataFrame:\n",
    "    students = [course.students for course in courses]\n",
    "\n",
    "    targets = set.intersection(*students)\n",
    "\n",
    "    def score(c: test_extract.Course) -> float:\n",
    "        class_size = len(c.students)\n",
    "        target_pop = len(set.intersection(targets, c.students))\n",
    "        if class_size < threshold:\n",
    "            return 0\n",
    "        return target_pop / class_size\n",
    "\n",
    "    courses = data.getCourses()\n",
    "    scores = map(score, courses)\n",
    "\n",
    "    recommendations = {\n",
    "        'code': [course.id for course in courses],\n",
    "        'course': courses,\n",
    "        'score' : list(scores),\n",
    "        'size': [len(course.students) for course in courses]\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame(recommendations).sort_values('score', ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " As usual, when using a ratio-based scoring method, we run into problems at the\n",
    " extreme low ends of the denominator (in this case, class size). We can see why\n",
    " in this chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = translate([\"CS2110\", \"CS2800\", \"CS2850\", \"CS1110\"])\n",
    "\n",
    "df = recommend_bystudent_prop(beta)\n",
    "show_results(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " It should be pretty clear from the scatterplot above that we're skirting a\n",
    " critical problem. Let's demonstrate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = translate([\"CS2110\", \"CS2800\", \"CS2850\", \"CS1110\", \"CS4740\"])\n",
    "\n",
    "df = recommend_bystudent_prop(beta)\n",
    "show_results(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Obviously the model isn't actually very robust against adding classes. When we\n",
    " add a small class, the target population becomes so small that we tend to get\n",
    " scattered and random results. There's an argument to be made here that this\n",
    " could actually provide the kind of diversity of recommendation that Kilczec is\n",
    " looking for, but it doesn't seem to me that these recommendations are really\n",
    " that helpful for a given student. One way to improve might be to \"soften\" our\n",
    " target student pool - to include results from more students, but simply\n",
    " prioritize students who have taken classes in the input set."
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
